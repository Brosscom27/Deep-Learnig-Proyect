# Proyecto DIME-MEX 2025: ClasificaciÃ³n Multimodal de Discursos de Odio

Este proyecto forma parte del curso **DIME-MEX 2025** ([enlace oficial](https://sites.google.com/view/dimemex-2025/important-dates?authuser=0)) y tiene como objetivo desarrollar un modelo de clasificaciÃ³n de discursos de odio en memes, utilizando informaciÃ³n tanto visual como textual.

## ðŸ“Œ DescripciÃ³n del Proyecto

El proyecto aborda el problema de detecciÃ³n automÃ¡tica de contenido ofensivo en memes, considerando la naturaleza multimodal del problema: imÃ¡genes con texto superpuesto que, en conjunto, pueden transmitir discursos de odio.

Nuestra primera soluciÃ³n combina tÃ©cnicas de procesamiento de lenguaje natural y visiÃ³n por computadora mediante el uso de:

- **BERT**: modelo de lenguaje preentrenado para extraer embeddings del texto.
- **CNN (Convolutional Neural Network)**: para procesar las imÃ¡genes y extraer sus caracterÃ­sticas visuales.
- **ConcatenaciÃ³n Multimodal**: se unen los embeddings de imagen y texto para ser clasificados por una capa densa final.
- **CLIP (Contrastive Languageâ€“Image Pre-training)**: modelo para tareas multimodales que aprende conceptos visuales de manera eficaz a partir de la supervisiÃ³n del lenguaje natural.

## ðŸ§  Arquitectura

```text
[Imagen] -> CNN -> Embedding Visual
[Texto]  -> BERT -> Embedding Textual
      â†“             â†“
      ---- ConcatenaciÃ³n ----
                 â†“
           Capa(s) Densas
                 â†“
         PredicciÃ³n (Inofensivo / Inapropiado / Discurso de Odio)
